{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed910e8-5c1f-4142-ae58-c2cadd51d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import os\n",
    "from os import listdir\n",
    "import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Sequence, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Lightning\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78726e93-05d6-40a7-aff5-47087745b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf06c40-6b5d-419e-9397-a6ea74a3de83",
   "metadata": {},
   "source": [
    "# Function to load image data\n",
    "\n",
    "First we need to define some functions to load data from image file with geographic information. The must frequently used library for geo raster data is the rasterio wrapping of GDAL library (c++). This library enable to read raster data with a defined number of bands and a specified windows (sub part) of the image. The abilities to only load a part of an image is useful as geographical image (raster) could be very huge, i.e more than 10 thousand pixel width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073ba97-3853-431e-a821-d5d6f69f7258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we defined a simple loader we load some selected band of image band with all width/height\n",
    "def geoimage_simple_load(img_path, band_indices):\n",
    "    \"\"\"\n",
    "    load a geo image in numpy array of shape C * W * H\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with rasterio.open(img_path) as src:\n",
    "        img_array = src.read(indexes=band_indices)\n",
    "    \n",
    "    if img_array.ndim == 2:\n",
    "        img_array = img_array[np.newaxis, ...]\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "def geoimage_load_tile(img_path, band_indices, window):\n",
    "    \"\"\"\n",
    "    \n",
    "    windows : tuple with col_off, row_off, width, height\n",
    "    \"\"\"\n",
    "    \n",
    "    with rasterio.open(img_path) as src:\n",
    "        img_array = src.read(window=Window(*window), indexes=band_indices)\n",
    "    \n",
    "    if img_array.ndim == 2:\n",
    "        img_array = img_array[np.newaxis, ...]\n",
    "    \n",
    "    return img_array  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d51af-1ffe-49fb-808d-bd297f1f8663",
   "metadata": {},
   "source": [
    "# PreProcess or transform image data\n",
    "\n",
    "## common transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6bd924-81ff-44cf-8aad-2fb7dc2f6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_dict(image: np.ndarray, mask:np.ndarray) -> Dict[str, Any] :\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return {\"image\": image, \"mask\": mask}\n",
    "            \n",
    "\n",
    "class BasicTransform():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params: Dict[Any, Any] = {}\n",
    "        self.img_only: bool = False\n",
    "        self.mask_only: bool = False\n",
    "        \n",
    "    def __call__(self, image: np.ndarray, mask:np.ndarray) -> Dict[str, Any]:\n",
    "        if self.img_only :\n",
    "            return {\n",
    "                \"image\": self.apply_to_img(image),\n",
    "                \"mask\": mask}\n",
    "        elif self.mask_only :\n",
    "            return {\n",
    "                \"image\": image,\n",
    "                \"mask\": self.apply_to_mask(mask)}\n",
    "        else:\n",
    "            return {\n",
    "                \"image\": self.apply_to_img(image),\n",
    "                \"mask\": self.apply_to_mask(mask)}\n",
    "    \n",
    "    def apply_to_img(self, img: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def apply_to_mask(self, mask: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class HWC_to_CHW(BasicTransform):\n",
    "    \n",
    "    def __init__(self, img_only: bool=False, mask_only : bool = False) :\n",
    "        super(CHW_to_HWC, self).__init__()\n",
    "        self.img_only = img_only\n",
    "        self.mask_only = mask_only\n",
    "    \n",
    "    @staticmethod\n",
    "    def swap_axes(array : np.ndarray) -> np.ndarray:\n",
    "        # swap the axes order from (rows, columns, bands) to (band, rows, columns)\n",
    "        array = np.ma.transpose(array, [2, 0, 1])\n",
    "        return array\n",
    "    \n",
    "    def apply_to_img(self, img: np.ndarray) -> np.ndarray:\n",
    "        return HWC_to_CHW.swap_axes(img)\n",
    "        \n",
    "    def apply_to_mask(self, mask: np.ndarray) -> np.ndarray:\n",
    "        return HWC_to_CHW.swap_axes(mask)\n",
    "        \n",
    "    \n",
    "class CHW_to_HWC(BasicTransform):\n",
    "    \n",
    "    def __init__(self, img_only: bool=False, mask_only : bool = False) :\n",
    "        super(CHW_to_HWC, self).__init__()\n",
    "        self.img_only = img_only\n",
    "        self.mask_only = mask_only\n",
    "    \n",
    "    @staticmethod\n",
    "    def swap_axes(array : np.ndarray) -> np.ndarray:\n",
    "        # swap the axes order from (bands, rows, columns) to (rows, columns, bands)\n",
    "        array = np.ma.transpose(array, [1, 2, 0])\n",
    "        return array\n",
    "    \n",
    "    def apply_to_img(self, img: np.ndarray) -> np.ndarray:\n",
    "        return CHW_to_HWC.swap_axes(img)\n",
    "        \n",
    "    def apply_to_mask(self, mask: np.ndarray) -> np.ndarray:\n",
    "        return CHW_to_HWC.swap_axes(mask)\n",
    "        \n",
    "\n",
    "class ToTorchTensor(BasicTransform):\n",
    "    \n",
    "    def __init__(self, img_only: bool=False, mask_only : bool = False) :\n",
    "        super(ToTorchTensor, self).__init__()\n",
    "        self.img_only = img_only\n",
    "        self.mask_only = mask_only\n",
    "    \n",
    "    def apply_to_img(self, img: np.ndarray) :\n",
    "        return torch.from_numpy(img).type(torch.float32)\n",
    "        \n",
    "    def apply_to_mask(self, mask: np.ndarray) :\n",
    "        return  torch.from_numpy(mask).type(torch.float32)\n",
    "\n",
    "\n",
    "class TensorToArray(BasicTransform):\n",
    "    \n",
    "    def __init__(self, img_only: bool=False, mask_only : bool = False) :\n",
    "        super(TensorToArray, self).__init__()\n",
    "        self.img_only = img_only\n",
    "        self.mask_only = mask_only\n",
    "    \n",
    "    def apply_to_img(self, img ) -> np.ndarray:\n",
    "        return img.cpu().numpy()\n",
    "        \n",
    "    def apply_to_mask(self, mask ) -> np.ndarray:\n",
    "        return mask.cpu().numpy()\n",
    "        \n",
    "        \n",
    "class ScaleImageToFloat(BasicTransform):\n",
    "    \"\"\"\n",
    "    scale an input image to float image between [0, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, scale_factor : float = 255, clip : bool = False) :\n",
    "        super(ScaleImageToFloat, self).__init__()\n",
    "        self.img_only = True\n",
    "        self.scale_factor = scale_factor\n",
    "        self.clip = clip\n",
    "    \n",
    "    def apply_to_img(self, img: np.ndarray) -> np.ndarray:\n",
    "        img = np.multiply(img, 1./self.scale_factor, dtype=np.float32)\n",
    "        if self.clip :\n",
    "            return np.clip(img, 0, 1)\n",
    "        else :\n",
    "            return img\n",
    "\n",
    "        \n",
    "class FloatImageToByte(BasicTransform):\n",
    "    \"\"\"\n",
    "    scale an input image from [0-1] to [0-255] mainly ofr rgb display purpose\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, clip : bool = False) :\n",
    "        super(FloatImageToByte, self).__init__()\n",
    "        self.img_only = True\n",
    "        self.scale_factor = 255\n",
    "        self.clip = clip\n",
    "    \n",
    "    def apply_to_img(self, img: np.ndarray) -> np.ndarray:\n",
    "        img = np.multiply(img, self.scale_factor, dtype=np.float32)\n",
    "        img = img.astype(np.uint8)\n",
    "        if self.clip :\n",
    "            return np.clip(img, 0, 255)\n",
    "        else :\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ff2a7-4de8-41fb-988f-d4ae2f7dffdd",
   "metadata": {},
   "source": [
    "# Prepair Gers data\n",
    "\n",
    "We have to prepocess some data in order to use Gers Dataset in our expriment.\n",
    "\n",
    " * load define label metadata : name, color (lut),  associated shapefile\n",
    " * load image bounds and join with fold group\n",
    " * load /adapt odeon csv of patch dataset for testing and comparision between two dataset loading strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f741eb3-811b-49d3-a9c2-75ca0aa0ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main parameters\n",
    "gers_dataset_root_dir = Path(\"/home/data/32_2019_prod\")\n",
    "\n",
    "path_data = gers_dataset_root_dir.joinpath(\"dataset_ocsng_gers_naf_fold\")\n",
    "image_bands = [1, 2, 3] \n",
    "mask_bands = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75fcd3e-d095-4789-bd56-c311be5664ca",
   "metadata": {},
   "source": [
    "Then we defined the naf nomenclature used on gers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b07b6-8d78-4718-8db4-eb44c275941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "naf_label = [\n",
    "    \"batiment\",\n",
    "    \"zone_permeable\",\n",
    "    \"zone_impermeable\",\n",
    "    \"piscine\",\n",
    "    \"sol_nus\",\n",
    "    \"surface-eau\",\n",
    "    \"neige\",\n",
    "    \"coupe\",\n",
    "    \"feuillus\",\n",
    "    \"conifere\",\n",
    "    \"brousaille\",\n",
    "    \"vigne\",\n",
    "    \"culture\",\n",
    "    \"terre_labouree\",\n",
    "    \"autre\"\n",
    "]\n",
    "\n",
    "naf_lut = np.array([\n",
    " [219,  14, 154],\n",
    " [114, 113, 112],\n",
    " [248,  12,   0],\n",
    " [ 61, 230, 235],\n",
    " [169, 113,   1],\n",
    " [ 21,  83, 174],\n",
    " [255, 255, 255],\n",
    " [138, 179, 160],\n",
    " [ 70, 228, 131],\n",
    " [ 25,  74,  38],\n",
    " [243, 166,  13],\n",
    " [102,   0, 130],\n",
    " [255, 243,  13],\n",
    " [228, 223, 124],\n",
    " [  0,   0,   0]\n",
    "])\n",
    "\n",
    "label_names = [\n",
    "    \"batiment\",\n",
    "    \"zone_permeable\",\n",
    "    \"zone_impermeable\",\n",
    "    \"piscine\",\n",
    "    \"sol_nus\",\n",
    "    \"surface-eau\",\n",
    "    \"neige\",\n",
    "    \"coupe\",\n",
    "    \"feuillus\",\n",
    "    \"conifere\",\n",
    "    \"brousaille\",\n",
    "    \"vigne\",\n",
    "    \"culture\",\n",
    "    \"terre_labouree\"\n",
    "]\n",
    "label_shp = [\n",
    "    \"mask_32_2019_01-batiment.shp\",          \n",
    "    \"mask_32_2019_02-zone-permeable.shp\",\n",
    "    \"mask_32_2019_03-zone-impermeable.shp\",\n",
    "    \"mask_32_2019_04-piscine.shp\",\n",
    "    \"mask_32_2019_05-sol-nu.shp\",\n",
    "    \"mask_32_2019_06-surface-eau.shp\", \n",
    "    \"mask_32_2019_07-neige.shp\",\n",
    "    \"mask_32_2019_08-naf_coupe.shp\",\n",
    "    \"mask_32_2019_09-naf_feuillus.shp\", \n",
    "    \"mask_32_2019_10-naf_conifere.shp\",\n",
    "    \"mask_32_2019_11-naf_landes-ligneuses.shp\",\n",
    "    \"mask_32_2019_12-naf_vignes.shp\",\n",
    "    \"mask_32_2019_13-naf_cultures.shp\",\n",
    "    \"mask_32_2019_14-naf-terre_labouree.shp\"\n",
    "]\n",
    "label_channel = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8028a3c7-a0ea-4589-8493-bc5bc02cedf0",
   "metadata": {},
   "source": [
    "### loading of train val test patch for set/fold 4\n",
    "\n",
    "as image path in csv file are in absolut path we need to replace old one with new corresponding to current root dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca69a1-17bb-4f35-846e-8dd604aa46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(path_data, 'train_4_fold_2-fold_3-fold_4.csv'), names=['img', 'msk'])\n",
    "df_val = pd.read_csv(os.path.join(path_data, 'val_4_fold_1.csv'), names=['img', 'msk'])\n",
    "df_test = pd.read_csv(os.path.join(path_data, 'test_4_fold_5.csv'), names=['img', 'msk'])\n",
    "\n",
    "# change abs dir to new root path\n",
    "old_root_dir = Path(\"/home/ign.fr/ndavid/test_odeon_ocsng_32\")\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df[\"img\"] =  df[\"img\"].str.replace(str(old_root_dir), str(gers_dataset_root_dir), regex=False)\n",
    "    df[\"msk\"] =  df[\"msk\"].str.replace(str(old_root_dir), str(gers_dataset_root_dir), regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e32c4-a82c-462b-aec4-1b61a6029242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a71f46-da0e-4e39-a0ed-2613b7a17a47",
   "metadata": {},
   "source": [
    "### loading images list with corresponding fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2de1c-b213-49a7-85b9-86051723e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_dir(img_dir : Path):\n",
    "    files = [img_dir.joinpath(f) for f in listdir(img_dir) if img_dir.joinpath(f).is_file()]\n",
    "    img_files = [f for f in files if f.suffix.lower() in [\".tif\", \".jp2\"]]\n",
    "    img_rows = []\n",
    "    for img_path in img_files:\n",
    "        with rasterio.open(img_path) as ds:\n",
    "            width = ds.width # x axis\n",
    "            height = ds.height # y axis\n",
    "            transform = ds.transform\n",
    "            res_x = transform[0]\n",
    "            res_y = transform[4]\n",
    "            ul_x = transform[2]\n",
    "            ul_y = transform[5]\n",
    "            path = str(img_path)\n",
    "            name = str(img_path.stem)\n",
    "            row = {\n",
    "                \"name\" : name,\n",
    "                \"width\" : width,\n",
    "                \"height\" : height,\n",
    "                \"res_x\" : res_x,\n",
    "                \"res_y\" : res_y,\n",
    "                \"ul_x\" : ul_x,\n",
    "                \"ul_y\" : ul_y,\n",
    "                \"path\" : path,\n",
    "                \"transform\" : transform\n",
    "            }\n",
    "            img_rows.append(row)\n",
    "    img_df = pd.DataFrame(img_rows)\n",
    "    return img_df\n",
    "\n",
    "# utils to load fold and image lists\n",
    "rvb_dir = gers_dataset_root_dir.joinpath(\"IMAGES_RVB\")\n",
    "roi_shp_path = gers_dataset_root_dir.joinpath(\"kfold_32\", \"zones_vt_32.shp\")\n",
    "\n",
    "gers_rvb_df = load_img_dir(rvb_dir)\n",
    "gers_rvb_df[\"roi_name\"] = gers_rvb_df[\"name\"].str[0:-4]\n",
    "gers_rvb_df = gers_rvb_df.set_index(\"roi_name\")\n",
    "\n",
    "roi_gdf = gpd.read_file(roi_shp_path)\n",
    "roi_gdf = roi_gdf[[\"id\",\"kfold\"]]\n",
    "roi_gdf[\"roi_name\"] = roi_gdf[\"id\"].apply(lambda x: f\"FR_032_2019_{x[0].upper()}-{x[1:].zfill(2)}\")\n",
    "roi_gdf = roi_gdf.set_index(\"roi_name\")\n",
    "\n",
    "gers_rvb_df = gers_rvb_df.join(roi_gdf, lsuffix='img', rsuffix='shp')\n",
    "gers_rvb_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec110b9-b4b6-41fb-a1b9-e48008f76788",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame(data={\"names\" : label_names, \"shp\" : label_shp, \"channel\" : label_channel})\n",
    "label_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee1bb8-6e08-465b-908b-6272d23bac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mask image columns\n",
    "gers_rvb_df = gers_rvb_df.rename(columns={\"path\": \"rvb_path\"})\n",
    "gers_rvb_df[\"msk_path\"] =  gers_rvb_df[\"rvb_path\"].str.replace(\"IMAGES_RVB\", \"IMAGES_MASK\", regex=False)\n",
    "gers_rvb_df[\"msk_path\"] =  gers_rvb_df[\"msk_path\"].str.replace(\"_RVB.tif\", \"-MASK.tif\", regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a2be46-7278-423e-b74e-b2c1d4d67ff9",
   "metadata": {},
   "source": [
    "#### rasterize data\n",
    "\n",
    "If not done yet we need to rasterize shapefile data by zone/images bounds before using it in a Torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37739fdc-f1ea-43ab-a2ec-8b3a222bb532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterize image\n",
    "img_rvb_list = gers_rvb_df[\"rvb_path\"].values\n",
    "in_shp_dir = gers_dataset_root_dir.joinpath(\"MASK_SHP\", \"SAISIE\")\n",
    "out_mask_dir = gers_dataset_root_dir.joinpath(\"IMAGES_MASK\")\n",
    "\n",
    "from rasterio import features\n",
    "\n",
    "for img_filename in img_rvb_list :\n",
    "    img_path = Path(img_filename)\n",
    "    print(img_path.stem)\n",
    "    with rasterio.open(img_path) as src_dataset:\n",
    "        kwds = src_dataset.profile\n",
    "    \n",
    "    kwds['driver'] = 'GTiff'\n",
    "    kwds['count'] = len(label_df)\n",
    "    \n",
    "    out_mask = out_mask_dir.joinpath(f\"{img_path.stem[:-4]}-MASK.tif\")\n",
    "    with rasterio.open(out_mask, 'w', **kwds) as dst_dataset:\n",
    "        out_transform = dst_dataset.transform\n",
    "        xmin, ymin, xmax, ymax  = dst_dataset.bounds\n",
    "        width = dst_dataset.width # x axis\n",
    "        height = dst_dataset.height # y axis\n",
    "        out_shape = (height, width)\n",
    "        # print(out_shape)\n",
    "        for ind in label_df.index:\n",
    "            label_name = label_df[\"names\"][ind]\n",
    "            label_shp = label_df[\"shp\"][ind]\n",
    "            out_channel = int(label_df[\"channel\"][ind])\n",
    "            label_path = in_shp_dir.joinpath(label_shp)\n",
    "            # print(label_shp)\n",
    "            # print(out_channel)\n",
    "            # load shapefile to geopandas\n",
    "            label_gdf = gpd.read_file(label_path)\n",
    "            # overlay by image bounds ?\n",
    "            label_gdf = label_gdf.cx[xmin:xmax, ymin:ymax]\n",
    "            # this is where we create a generator of geom, value pairs to use in rasterizing\n",
    "            if len(label_gdf) !=0 :\n",
    "                shapes = ((geom, 1) for geom in label_gdf.geometry)\n",
    "                burned = features.rasterize(shapes=shapes, out_shape=out_shape, fill=0, transform=out_transform)\n",
    "            else :\n",
    "                burned = np.zeros(out_shape, dtype=np.uint8)\n",
    "            # print(burned.shape)\n",
    "            dst_dataset.write(burned.astype(rasterio.uint8), out_channel+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4097f5-ea92-4dfc-8f3e-6efd72e3aa8a",
   "metadata": {},
   "source": [
    "### test rasterization display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc7c46-e58a-4713-a3dc-d5d5de237ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rvb_list = gers_rvb_df[\"rvb_path\"].values\n",
    "out_mask_dir = gers_dataset_root_dir.joinpath(\"IMAGES_MASK\")\n",
    "test_mask = out_mask_dir.joinpath(\"FR_032_2019_U-17-MASK.tif\")\n",
    "\n",
    "with rasterio.open(test_mask) as mask_ds:\n",
    "    mask_array = mask_ds.read()\n",
    "    mask_array = np.argmax(mask_array, axis=0)\n",
    "    mask_array = np.take(naf_lut, mask_array, axis=0)\n",
    "\n",
    "print(mask_array.shape)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(mask_array[1024:2048,2048:3072])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67519fa-7853-49f1-bd0a-fbd53e290416",
   "metadata": {},
   "source": [
    "# Torch Dataset\n",
    "\n",
    "A torch dataset is a class who is responsible for loading item on a deep learning dataset. It is use to iterate on the train and val parts of the dataset on the treaining loop and on the test aprt when evaluating model results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2955ff-2f4a-42af-a75b-40ac91591f0d",
   "metadata": {},
   "source": [
    "### utils to display patch/batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e851ff9f-c065-4191-a14f-a7d03245d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some function to display patch and control dataset functionnality\n",
    "\n",
    "def view_patch(data, transforms=None):\n",
    "    \"\"\"\n",
    "    dataset: dataset contains tile & mask \n",
    "    idx : index \n",
    "    \n",
    "    Returns : plot tile & mask  \n",
    "    \"\"\"    \n",
    "    if transforms is not None :\n",
    "        for t in transforms:\n",
    "            data = t(**data)\n",
    "                \n",
    "    raster_tile = data[\"image\"]\n",
    "    raster_gt = data[\"mask\"]\n",
    "    \n",
    "    figure, ax = plt.subplots(nrows=1, ncols=2,figsize=(10,6))\n",
    "    \n",
    "    ax[0].imshow(raster_tile)\n",
    "    ax[0].set_title('Raster Tile')\n",
    "    ax[0].set_axis_off()\n",
    "    \n",
    "    ax[1].imshow(raster_gt)\n",
    "    ax[1].set_title('Raster Gt')\n",
    "    ax[1].set_axis_off()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def view_batch(batch_data, transforms=None, size = None, ncols = None):\n",
    "    \n",
    "    raster_tiles = batch_data[\"image\"]\n",
    "    raster_gts = batch_data[\"mask\"]\n",
    "    \n",
    "    batch_size = raster_tiles.shape[0]\n",
    "    ncols = batch_size\n",
    "    if size is not None :\n",
    "        ncols = size\n",
    "    \n",
    "    figure, ax = plt.subplots(nrows=2, ncols=ncols, figsize=(20, 8))    \n",
    "        \n",
    "    for idx in range(ncols):\n",
    "        if transforms is not None :\n",
    "            data = {\n",
    "                \"image\" : raster_tiles[idx],\n",
    "                \"mask\" : raster_gts[idx]}\n",
    "            for t in transforms:\n",
    "                data = t(**data)\n",
    "        \n",
    "            raster_tile = data[\"image\"]\n",
    "            raster_gt = data[\"mask\"]\n",
    "        else :\n",
    "            raster_tile = raster_tiles[idx]\n",
    "            raster_gt = raster_gts[idx]\n",
    "        \n",
    "        ax[0][idx].imshow(raster_tile)\n",
    "        ax[0][idx].set_axis_off()\n",
    "\n",
    "        ax[1][idx].imshow(raster_gt)\n",
    "        ax[1][idx].set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "class ToRgbDisplay(BasicTransform):\n",
    "    \"\"\"\n",
    "    scale an input image to float image between [0, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, color_compo : str = None, channels_display : List[int] = None, lut : np.array =None) :\n",
    "        \"\"\"\n",
    "        \n",
    "        channels_display : list of channel to display in r,g,b order if dim 3, channel dto display if dim 1\n",
    "        \"\"\"\n",
    "        \n",
    "        super(ToRgbDisplay, self).__init__()\n",
    "        if color_compo is None and channels_display is None:\n",
    "            # set rgb as first three channel\n",
    "            self.color_compo = \"rgb\"\n",
    "            self.channels_display = [0,1,2]\n",
    "        \n",
    "        if lut is not None:\n",
    "            self.lut = lut\n",
    "        else :\n",
    "            self.lut = None\n",
    "            \n",
    "        if len(self.channels_display) != 1 and len(self.channels_display) !=  3 :\n",
    "            raise ValueError(\"number of channel to display should be 1 or 3 \")\n",
    "    \n",
    "    def apply_to_img(self, img: np.ndarray) -> np.ndarray:\n",
    "        img = img[:,:,self.channels_display]\n",
    "        return img\n",
    "\n",
    "    def apply_to_mask(self, mask: np.ndarray) -> np.ndarray:\n",
    "        mask = np.argmax(mask, axis=0)\n",
    "        if self.lut is not None:\n",
    "            # mask = self.lut[mask]\n",
    "            mask = np.take(self.lut, mask, axis=0)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65663fa7-f049-4613-9162-97ddf856804c",
   "metadata": {},
   "source": [
    "## simple patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753307d-f729-41aa-b760-a9c943ce28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, image_files, mask_files, transforms=None, image_bands=None,\n",
    "                 mask_bands=None):\n",
    "        self.image_files = image_files\n",
    "        self.image_bands = image_bands\n",
    "        self.mask_files = mask_files\n",
    "        self.mask_bands = mask_bands\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.load_array = geoimage_simple_load\n",
    "        self.format_data = format_to_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get path\n",
    "        image_file = self.image_files[index]\n",
    "        mask_file = self.mask_files[index]\n",
    "\n",
    "        # load array\n",
    "        img = self.load_array(\n",
    "            image_file,\n",
    "            band_indices=self.image_bands)\n",
    "\n",
    "        msk  = self.load_array(\n",
    "            mask_file,\n",
    "            band_indices=self.mask_bands)\n",
    "\n",
    "        data = self.format_data(image = img, mask = msk)\n",
    "        \n",
    "        if self.transforms is not None :\n",
    "            for t in self.transforms:\n",
    "                data = t(**data)\n",
    "\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ac9db-9c1a-454e-b8ad-445719ef06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms for test\n",
    "in_transforms = [\n",
    "    ScaleImageToFloat(scale_factor=255, clip=True),\n",
    "    ToTorchTensor()\n",
    "]\n",
    "# Data\n",
    "train_dataset = PatchDataset(\n",
    "    image_files=df_train['img'],\n",
    "    mask_files=df_train['msk'],\n",
    "    transforms=in_transforms,\n",
    "    image_bands=image_bands,\n",
    "    mask_bands=mask_bands)\n",
    "\n",
    "val_dataset = PatchDataset(\n",
    "    image_files=df_val['img'],\n",
    "    mask_files=df_val['msk'],\n",
    "    transforms=in_transforms,\n",
    "    image_bands=image_bands,\n",
    "    mask_bands=mask_bands)\n",
    "\n",
    "test_dataset = PatchDataset(\n",
    "    image_files=df_test['img'],\n",
    "    mask_files=df_test['msk'],\n",
    "    transforms=in_transforms,\n",
    "    image_bands=image_bands,\n",
    "    mask_bands=mask_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0df35f-7eb8-4b2a-a12b-ba7ca78c216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 170\n",
    "test_data = train_dataset[test_idx]\n",
    "print(f\" keys : {test_data.keys()}\")\n",
    "img_type =  test_data['image'].type()\n",
    "msk_type = test_data['mask'].type()\n",
    "print(f\" image type : {img_type}, mask type : {msk_type}\")\n",
    "\n",
    "display_transforms = [\n",
    "    TensorToArray(),\n",
    "    FloatImageToByte(clip=True),\n",
    "    CHW_to_HWC(img_only=True),\n",
    "    ToRgbDisplay(lut=naf_lut)\n",
    "]\n",
    "\n",
    "\n",
    "view_patch(test_data, transforms=display_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d2723-afc2-4148-a63b-458ecd0e08b1",
   "metadata": {},
   "source": [
    "## dataset with chop/clip when reading image\n",
    "\n",
    "Instead of first preprocess imagery to have a DL dataset into Ã  list of small patch image files we could also try to tile imagery on the fly based on the original large aerial/satellite imagery. \n",
    "\n",
    "Why could we be interrested in such functionnality :\n",
    " \n",
    " * first to test speed/data efficiency management. Large dataset could be simpler to manage and compress than a lot of small files and reading could also be as efficient.\n",
    " * the decision made when splitting could be changed on the fly. As pass to 256 to 512 pixels patchs\n",
    " * could act as a form of data augmentation without duplicate memory by sampling tile a different ovelerapping positions.\n",
    " * could help to change/test sampling by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8952f2-e5f3-4a10-8f60-8412821c2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_tile_from_img(img_shape: Tuple[int, int], tile_size: int) -> int :\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    nb_tile_col = img_shape[0] // tile_size\n",
    "    nb_tile_row = img_shape[1] // tile_size\n",
    "    return  nb_tile_col*nb_tile_row\n",
    "\n",
    "def get_img_windows_list(img_shape: Tuple[int, int], tile_size: int) :\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    col_step = [col for col in range(0, img_shape[0], tile_size)]\n",
    "    col_step.append(img_shape[0])\n",
    "    row_step =  [row for row in range(0, img_shape[1], tile_size)]\n",
    "    row_step.append(img_shape[1])\n",
    "\n",
    "    windows_list = []\n",
    "    for i, j in itertools.product(range(0, len(col_step)-1), \n",
    "                                  range(0, len(row_step)-1)):\n",
    "        windows_list.append(tuple((\n",
    "           row_step[j], \n",
    "           col_step[i], \n",
    "           row_step[j+1]- row_step[j],\n",
    "           col_step[i+1]- col_step[i])))\n",
    "    return windows_list\n",
    "\n",
    "    \n",
    "class LargeImageDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, image_files, mask_files, tile_size=512, transforms=None, image_bands=None, mask_bands=None):\n",
    "        self.image_files = image_files\n",
    "        self.image_bands = image_bands\n",
    "        self.tile_size = tile_size\n",
    "        self.mask_files = mask_files\n",
    "        self.mask_bands = mask_bands\n",
    "        self.transforms = transforms\n",
    "        self.format_data = format_to_dict\n",
    "        \n",
    "        self.load_array = geoimage_load_tile\n",
    "        ## init tiles/windows list\n",
    "        self.tiles_list = []\n",
    "        for img_id, img_path in enumerate(self.image_files) :\n",
    "            with rasterio.open(img_path) as img_ds :\n",
    "                # shape dimension is [C, W, H ]\n",
    "                img_width = img_ds.width\n",
    "                img_heigth = img_ds.height\n",
    "                img_shape = img_ds.shape # shape = (H, W)\n",
    "                # print(f\" W={img_width}, H={img_heigth}, shape ={img_shape}\")\n",
    "            \n",
    "            windows_list = get_img_windows_list( img_shape, self.tile_size)\n",
    "            tile_img_list = [ (img_id, window) for window in windows_list ]\n",
    "            self.tiles_list.extend(tile_img_list)\n",
    "                \n",
    "        # shuffle list\n",
    "        random.shuffle(self.tiles_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tiles_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get path\n",
    "        idx, window = self.tiles_list[index]\n",
    "\n",
    "        # print(window)\n",
    "        # load array\n",
    "        img = self.load_array(\n",
    "            self.image_files[idx],\n",
    "            band_indices=self.image_bands,\n",
    "            window = window)\n",
    "        # print(img.shape)\n",
    "\n",
    "        msk  = self.load_array(\n",
    "            self.mask_files[idx],\n",
    "            band_indices=self.mask_bands,\n",
    "            window = window)\n",
    "        # print(msk.shape)\n",
    "\n",
    "        data = self.format_data(image = img, mask = msk)\n",
    "        \n",
    "        if self.transforms is not None :\n",
    "            for t in self.transforms:\n",
    "                data = t(**data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987e390-9718-46ac-9be4-4172c156b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files_train = gers_rvb_df[\"rvb_path\"].values\n",
    "mask_files_train = gers_rvb_df[\"msk_path\"].values\n",
    "print(image_files_train[0:5])\n",
    "print(mask_files_train[0:5])\n",
    "\n",
    "train_dataset_tile = LargeImageDataset(\n",
    "    image_files=image_files_train,\n",
    "    mask_files=mask_files_train,\n",
    "    tile_size = 512,\n",
    "    transforms=None,\n",
    "    image_bands=image_bands,\n",
    "    mask_bands=mask_bands[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca997db2-3df7-4c3b-b249-e3d6b0956c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_last_transform = CHW_to_HWC(img_only=True)\n",
    "display_patch_transform = ToRgbDisplay( lut=naf_lut)\n",
    "\n",
    "test_data = train_dataset_tile[142]\n",
    "view_patch(test_data, transforms=[channel_last_transform, display_patch_transform])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4864a5b-b320-4920-88ab-6ac2e38102f4",
   "metadata": {},
   "source": [
    "# Lighning Datamodule\n",
    "\n",
    "we use datamodule to manage fold loading setup and some other utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c6cb7-2b7a-4ca8-9f52-8e0f79d94fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerriaDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(\n",
    "        self, data_df, transforms= None , img_col = \"images\", img_bands = None, mask_col = \"mask\", mask_bands = None,\n",
    "        group_col = \"fold\", set_config = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.batch_size = 4\n",
    "        self.tile_size = 512\n",
    "        self.num_workers = 2\n",
    "        \n",
    "        self.transform = transforms\n",
    "        self.image_bands = image_bands\n",
    "        self.mask_band = mask_bands\n",
    "        \n",
    "        self.data_df = data_df\n",
    "        self.img_col = img_col\n",
    "        self.mask_col = mask_col\n",
    "        self.group_col = group_col\n",
    "        if set_config is None :\n",
    "            self.set_config = {\n",
    "                \"train\" : [\"train\"],\n",
    "                \"val\" : [\"val\"],\n",
    "                \"test\" : [\"test\"] }\n",
    "        else:\n",
    "            self.set_config = set_config\n",
    "        \n",
    "                 \n",
    "    def prepare_data(self):\n",
    "        # rasterize from vector ?\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_config = self.set_config[\"train\"]\n",
    "            train_df = self.data_df[self.data_df[self.group_col].isin(train_config)]\n",
    "            image_files_train = train_df[self.img_col].values\n",
    "            mask_files_train = train_df[self.mask_col].values\n",
    "            self.train_dataset = LargeImageDataset(\n",
    "                image_files=image_files_train,\n",
    "                mask_files=mask_files_train,\n",
    "                tile_size = self.tile_size,\n",
    "                transforms=self.transform,\n",
    "                image_bands=self.image_bands,\n",
    "                mask_bands=self.mask_band)\n",
    "            \n",
    "            val_config = self.set_config[\"val\"]\n",
    "            val_df = self.data_df[self.data_df[self.group_col].isin(val_config)]\n",
    "            image_files_val = val_df[self.img_col].values\n",
    "            mask_files_val = val_df[self.mask_col].values\n",
    "            self.val_dataset = LargeImageDataset(\n",
    "                image_files=image_files_val,\n",
    "                mask_files=mask_files_val,\n",
    "                tile_size = self.tile_size,\n",
    "                transforms=self.transform,\n",
    "                image_bands=self.image_bands,\n",
    "                mask_bands=self.mask_band)\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            test_config = self.set_config[\"test\"]\n",
    "            test_df = self.data_df[self.data_df[self.group_col].isin(test_config)]\n",
    "            image_files_test = test_df[self.img_col].values\n",
    "            mask_files_test = test_df[self.mask_col].values\n",
    "            self.val_dataset = LargeImageDataset(\n",
    "                image_files=image_files_test,\n",
    "                mask_files=mask_files_test,\n",
    "                tile_size = self.tile_size,\n",
    "                transforms=self.transform,\n",
    "                image_bands=self.image_bands,\n",
    "                mask_bands=self.mask_band)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers = self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers = self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers = self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354994b9-7977-47a1-a43b-400555369acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gers_set_config = {\n",
    "    \"set1\" : {\n",
    "        \"train\" : [3, 4, 5],\n",
    "        \"val\" : [2],\n",
    "        \"test\" : [1] },\n",
    "    \"set2\" : {\n",
    "        \"train\" : [4, 5, 1],\n",
    "        \"val\" : [3],\n",
    "        \"test\" : [2] },\n",
    "    \"set3\" : {\n",
    "        \"train\" : [5, 1, 2],\n",
    "        \"val\" : [4],\n",
    "        \"test\" : [3] },\n",
    "    \"set4\" : {\n",
    "        \"train\" : [1, 2, 3],\n",
    "        \"val\" : [5],\n",
    "        \"test\" : [4] },\n",
    "    \"set5\" : {\n",
    "        \"train\" : [2, 3, 4],\n",
    "        \"val\" : [1],\n",
    "        \"test\" : [5] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c721c5-24f0-4c80-975a-877ff1696aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms for test\n",
    "in_transforms = [\n",
    "    ScaleImageToFloat(scale_factor=255, clip=True),\n",
    "    ToTorchTensor()\n",
    "]\n",
    "\n",
    "train_config = gers_set_config[\"set5\"][\"train\"]\n",
    "train_df = gers_rvb_df[gers_rvb_df[\"kfold\"].isin(train_config)]\n",
    "image_files_train = train_df[\"rvb_path\"].values\n",
    "mask_files_train = train_df[\"msk_path\"].values\n",
    "train_dataset = LargeImageDataset(\n",
    "    image_files=image_files_train,\n",
    "    mask_files=mask_files_train,\n",
    "    tile_size = 512,\n",
    "    transforms=in_transforms,\n",
    "    image_bands=image_bands,\n",
    "    mask_bands=mask_bands[:-1])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4)\n",
    "\n",
    "display_transforms = [\n",
    "    TensorToArray(),\n",
    "    FloatImageToByte(clip=True),\n",
    "    CHW_to_HWC(img_only=True),\n",
    "    ToRgbDisplay(lut=naf_lut)\n",
    "]\n",
    "\n",
    "test_batch = next(iter(train_dataloader))\n",
    "view_batch(test_batch, size = 4, transforms = display_transforms)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b5e41-7cd4-4e01-8bd2-b17d291c1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms for test\n",
    "in_transforms = [\n",
    "    ScaleImageToFloat(scale_factor=255, clip=True),\n",
    "    ToTorchTensor()\n",
    "]\n",
    "gers_data_module_set5 = TerriaDataModule(\n",
    "    gers_rvb_df, \n",
    "    transforms = in_transforms,\n",
    "    img_col = \"rvb_path\",\n",
    "    img_bands = image_bands,\n",
    "    mask_col = \"msk_path\",\n",
    "    mask_bands = mask_bands[:-1],\n",
    "    group_col = \"kfold\",\n",
    "    set_config = gers_set_config[\"set5\"])\n",
    "\n",
    "gers_data_module_set5.setup()\n",
    "train_dataloader = gers_data_module_set5.train_dataloader()\n",
    "\n",
    "display_transforms = [\n",
    "    TensorToArray(),\n",
    "    FloatImageToByte(clip=True),\n",
    "    CHW_to_HWC(img_only=True),\n",
    "    ToRgbDisplay(lut=naf_lut)\n",
    "]\n",
    "\n",
    "test_batch = next(iter(train_dataloader))\n",
    "view_batch(test_batch, size = 4, transforms = display_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ec9d62-fe8d-4e02-be70-6168284e427f",
   "metadata": {},
   "source": [
    "## Test iteration dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ea12b-8bfe-4b8d-ab8b-acec3581b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_dataloader = gers_data_module_set5.train_dataloader()\n",
    "\n",
    "with tqdm(\n",
    "    total=len(img_train_dataloader), desc=f\"Large Image loader\",\n",
    "    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}]') as pbar:\n",
    "\n",
    "    for sample in img_train_dataloader:\n",
    "        images = sample['image']\n",
    "        masks = sample['mask']\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4dafa2-b312-48b5-9a84-99bf6f89bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_train_dataset = PatchDataset(\n",
    "    image_files=df_train['img'],\n",
    "    mask_files=df_train['msk'],\n",
    "    transforms=in_transforms,\n",
    "    image_bands=image_bands,\n",
    "    mask_bands=mask_bands)\n",
    "patch_train_dataloader = DataLoader(patch_train_dataset, batch_size=4, num_workers=4)\n",
    "\n",
    "with tqdm(\n",
    "    total=len(patch_train_dataloader), desc=f\"patch Image loader\",\n",
    "    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}]') as pbar:\n",
    "\n",
    "    for sample in patch_train_dataloader:\n",
    "        images = sample['image']\n",
    "        masks = sample['mask']\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0a554-0e27-45bf-a217-fa6e004784a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EOTorchLoader)",
   "language": "python",
   "name": "eotorchloader"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
