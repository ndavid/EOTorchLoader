{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dfc141-6411-4e68-b668-63fdc68649b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import os\n",
    "from os import listdir\n",
    "import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Sequence, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173c434-4ecf-411a-8138-7da8f1eb0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e7ce9-e645-475a-a5c5-f26d813e017e",
   "metadata": {},
   "source": [
    "# Prepair Gers data\n",
    "\n",
    "We have to prepocess some data in order to use Gers Dataset in our expriment.\n",
    "\n",
    " * load define label metadata : name, color (lut),  associated shapefile\n",
    " * load image bounds and join with fold group\n",
    " * load /adapt odeon csv of patch dataset for testing and comparision between two dataset loading strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88fa28b-8bba-4bf3-9892-8658eb588756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main parameters\n",
    "gers_dataset_root_dir = Path(\"/media/dlsupport/DATA1/32_2019_prod\")\n",
    "\n",
    "path_data = gers_dataset_root_dir.joinpath(\"dataset_ocsng_gers_naf_fold\")\n",
    "image_bands = [1, 2, 3] \n",
    "mask_bands = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89fc5b6-1305-4abf-84f8-36124bb60a9d",
   "metadata": {},
   "source": [
    "Then we defined the naf nomenclature used on gers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088bd713-3f63-4b7f-9d78-110ad55bdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "naf_label = [\n",
    "    \"batiment\",\n",
    "    \"zone_permeable\",\n",
    "    \"zone_impermeable\",\n",
    "    \"piscine\",\n",
    "    \"sol_nus\",\n",
    "    \"surface-eau\",\n",
    "    \"neige\",\n",
    "    \"coupe\",\n",
    "    \"feuillus\",\n",
    "    \"conifere\",\n",
    "    \"brousaille\",\n",
    "    \"vigne\",\n",
    "    \"culture\",\n",
    "    \"terre_labouree\",\n",
    "    \"autre\"\n",
    "]\n",
    "\n",
    "naf_lut = np.array([\n",
    " [219,  14, 154],\n",
    " [114, 113, 112],\n",
    " [248,  12,   0],\n",
    " [ 61, 230, 235],\n",
    " [169, 113,   1],\n",
    " [ 21,  83, 174],\n",
    " [255, 255, 255],\n",
    " [138, 179, 160],\n",
    " [ 70, 228, 131],\n",
    " [ 25,  74,  38],\n",
    " [243, 166,  13],\n",
    " [102,   0, 130],\n",
    " [255, 243,  13],\n",
    " [228, 223, 124],\n",
    " [  0,   0,   0]\n",
    "])\n",
    "\n",
    "label_names = [\n",
    "    \"batiment\",\n",
    "    \"zone_permeable\",\n",
    "    \"zone_impermeable\",\n",
    "    \"piscine\",\n",
    "    \"sol_nus\",\n",
    "    \"surface-eau\",\n",
    "    \"neige\",\n",
    "    \"coupe\",\n",
    "    \"feuillus\",\n",
    "    \"conifere\",\n",
    "    \"brousaille\",\n",
    "    \"vigne\",\n",
    "    \"culture\",\n",
    "    \"terre_labouree\"\n",
    "]\n",
    "label_shp = [\n",
    "    \"mask_32_2019_01-batiment.shp\",          \n",
    "    \"mask_32_2019_02-zone-permeable.shp\",\n",
    "    \"mask_32_2019_03-zone-impermeable.shp\",\n",
    "    \"mask_32_2019_04-piscine.shp\",\n",
    "    \"mask_32_2019_05-sol-nu.shp\",\n",
    "    \"mask_32_2019_06-surface-eau.shp\", \n",
    "    \"mask_32_2019_07-neige.shp\",\n",
    "    \"mask_32_2019_08-naf_coupe.shp\",\n",
    "    \"mask_32_2019_09-naf_feuillus.shp\", \n",
    "    \"mask_32_2019_10-naf_conifere.shp\",\n",
    "    \"mask_32_2019_11-naf_landes-ligneuses.shp\",\n",
    "    \"mask_32_2019_12-naf_vignes.shp\",\n",
    "    \"mask_32_2019_13-naf_cultures.shp\",\n",
    "    \"mask_32_2019_14-naf-terre_labouree.shp\"\n",
    "]\n",
    "label_channel = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff146736-924f-481e-b223-c418dda0e561",
   "metadata": {},
   "source": [
    "### loading of train val test patch for set/fold 4\n",
    "\n",
    "as image path in csv file are in absolut path we need to replace old one with new corresponding to current root dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50ba5a-e53d-48b6-a79b-0aef3358ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(path_data, 'train_4_fold_2-fold_3-fold_4.csv'), names=['img', 'msk'])\n",
    "df_val = pd.read_csv(os.path.join(path_data, 'val_4_fold_1.csv'), names=['img', 'msk'])\n",
    "df_test = pd.read_csv(os.path.join(path_data, 'test_4_fold_5.csv'), names=['img', 'msk'])\n",
    "\n",
    "# change abs dir to new root path\n",
    "old_root_dir = Path(\"/home/ign.fr/ndavid/test_odeon_ocsng_32\")\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df[\"img\"] =  df[\"img\"].str.replace(str(old_root_dir), str(gers_dataset_root_dir), regex=False)\n",
    "    df[\"msk\"] =  df[\"msk\"].str.replace(str(old_root_dir), str(gers_dataset_root_dir), regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45d7e1-b3ab-4b38-8947-48e482f5fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fad6ad-6994-470c-bacc-54dbc9a850b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for use in train code\n",
    "from eotorchloader.transform.scale import ScaleImageToFloat\n",
    "from eotorchloader.transform.tensor import ToTorchTensor\n",
    "from eotorchloader.dataset.patch_dataset import PatchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3b595-078d-4d8f-ab5f-16695c743c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display import\n",
    "from eotorchloader.transform.scale import FloatImageToByte\n",
    "from eotorchloader.transform.tensor import TensorToArray, CHW_to_HWC\n",
    "from eotorchloader.transform.display import ToRgbDisplay\n",
    "\n",
    "from eotorchloader.display.matplotlib import view_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248437d6-2336-4ba1-a34c-5f4265997689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms for test\n",
    "in_transforms = [\n",
    "    ScaleImageToFloat(scale_factor=255, clip=True),\n",
    "    ToTorchTensor()\n",
    "]\n",
    "# Data\n",
    "train_dataset = PatchDataset(\n",
    "    image_files=df_train['img'],\n",
    "    mask_files=df_train['msk'],\n",
    "    transforms=in_transforms,\n",
    "    image_bands=image_bands,\n",
    "    mask_bands=mask_bands)\n",
    "\n",
    "val_dataset = PatchDataset(\n",
    "    image_files=df_val['img'],\n",
    "    mask_files=df_val['msk'],\n",
    "    transforms=in_transforms,\n",
    "    image_bands=image_bands,\n",
    "    mask_bands=mask_bands)\n",
    "\n",
    "test_dataset = PatchDataset(\n",
    "    image_files=df_test['img'],\n",
    "    mask_files=df_test['msk'],\n",
    "    transforms=in_transforms,\n",
    "    image_bands=image_bands,\n",
    "    mask_bands=mask_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469786e0-615c-4ca6-9c67-4f866ad45e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 170\n",
    "test_data = train_dataset[test_idx]\n",
    "print(f\" keys : {test_data.keys()}\")\n",
    "img_type =  test_data['image'].type()\n",
    "msk_type = test_data['mask'].type()\n",
    "print(f\" image type : {img_type}, mask type : {msk_type}\")\n",
    "\n",
    "display_transforms = [\n",
    "    TensorToArray(),\n",
    "    FloatImageToByte(clip=True),\n",
    "    CHW_to_HWC(img_only=True),\n",
    "    ToRgbDisplay(lut=naf_lut)\n",
    "]\n",
    "\n",
    "view_patch(test_data, transforms=display_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbacc07-1553-4347-89d0-18545a5fe374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "patch_train_dataloader = DataLoader(train_dataset, batch_size=4, num_workers=4)\n",
    "\n",
    "with tqdm(\n",
    "    total=len(patch_train_dataloader), desc=f\"patch Image loader\",\n",
    "    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}]') as pbar:\n",
    "\n",
    "    for sample in patch_train_dataloader:\n",
    "        images = sample['image']\n",
    "        masks = sample['mask']\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36765b90-6b1a-4f1d-82fe-040b9eeede22",
   "metadata": {},
   "source": [
    "### loading images list with corresponding fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734d499-b61d-4494-b61a-cd57af46b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_dir(img_dir : Path):\n",
    "    files = [img_dir.joinpath(f) for f in listdir(img_dir) if img_dir.joinpath(f).is_file()]\n",
    "    img_files = [f for f in files if f.suffix.lower() in [\".tif\", \".jp2\"]]\n",
    "    img_rows = []\n",
    "    for img_path in img_files:\n",
    "        with rasterio.open(img_path) as ds:\n",
    "            width = ds.width # x axis\n",
    "            height = ds.height # y axis\n",
    "            transform = ds.transform\n",
    "            res_x = transform[0]\n",
    "            res_y = transform[4]\n",
    "            ul_x = transform[2]\n",
    "            ul_y = transform[5]\n",
    "            path = str(img_path)\n",
    "            name = str(img_path.stem)\n",
    "            row = {\n",
    "                \"name\" : name,\n",
    "                \"width\" : width,\n",
    "                \"height\" : height,\n",
    "                \"res_x\" : res_x,\n",
    "                \"res_y\" : res_y,\n",
    "                \"ul_x\" : ul_x,\n",
    "                \"ul_y\" : ul_y,\n",
    "                \"path\" : path,\n",
    "                \"transform\" : transform\n",
    "            }\n",
    "            img_rows.append(row)\n",
    "    img_df = pd.DataFrame(img_rows)\n",
    "    return img_df\n",
    "\n",
    "# utils to load fold and image lists\n",
    "rvb_dir = gers_dataset_root_dir.joinpath(\"IMAGES_RVB\")\n",
    "roi_shp_path = gers_dataset_root_dir.joinpath(\"kfold_32\", \"zones_vt_32.shp\")\n",
    "\n",
    "gers_rvb_df = load_img_dir(rvb_dir)\n",
    "gers_rvb_df[\"roi_name\"] = gers_rvb_df[\"name\"].str[0:-4]\n",
    "gers_rvb_df = gers_rvb_df.set_index(\"roi_name\")\n",
    "\n",
    "roi_gdf = gpd.read_file(roi_shp_path)\n",
    "roi_gdf = roi_gdf[[\"id\",\"kfold\"]]\n",
    "roi_gdf[\"roi_name\"] = roi_gdf[\"id\"].apply(lambda x: f\"FR_032_2019_{x[0].upper()}-{x[1:].zfill(2)}\")\n",
    "roi_gdf = roi_gdf.set_index(\"roi_name\")\n",
    "\n",
    "gers_rvb_df = gers_rvb_df.join(roi_gdf, lsuffix='img', rsuffix='shp')\n",
    "gers_rvb_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba4d2f-4617-4b67-8083-bd980369a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame(data={\"names\" : label_names, \"shp\" : label_shp, \"channel\" : label_channel})\n",
    "label_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f378a8-27ba-475e-a3af-0f0b3f0d32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mask image columns\n",
    "gers_rvb_df = gers_rvb_df.rename(columns={\"path\": \"rvb_path\"})\n",
    "gers_rvb_df[\"msk_path\"] =  gers_rvb_df[\"rvb_path\"].str.replace(\"IMAGES_RVB\", \"IMAGES_MASK\", regex=False)\n",
    "gers_rvb_df[\"msk_path\"] =  gers_rvb_df[\"msk_path\"].str.replace(\"_RVB.tif\", \"-MASK.tif\", regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f2ccd-4fa8-4120-9fc2-10c733580b66",
   "metadata": {},
   "source": [
    "#### rasterize data\n",
    "\n",
    "If not done yet we need to rasterize shapefile data by zone/images bounds before using it in a Torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef96b6e-deef-4deb-98f1-8064f9b5f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterize image\n",
    "img_rvb_list = gers_rvb_df[\"rvb_path\"].values\n",
    "in_shp_dir = gers_dataset_root_dir.joinpath(\"MASK_SHP\", \"SAISIE\")\n",
    "out_mask_dir = gers_dataset_root_dir.joinpath(\"IMAGES_MASK\")\n",
    "\n",
    "from rasterio import features\n",
    "\n",
    "for img_filename in img_rvb_list :\n",
    "    img_path = Path(img_filename)\n",
    "    print(img_path.stem)\n",
    "    with rasterio.open(img_path) as src_dataset:\n",
    "        kwds = src_dataset.profile\n",
    "    \n",
    "    kwds['driver'] = 'GTiff'\n",
    "    kwds['count'] = len(label_df)\n",
    "    \n",
    "    out_mask = out_mask_dir.joinpath(f\"{img_path.stem[:-4]}-MASK.tif\")\n",
    "    with rasterio.open(out_mask, 'w', **kwds) as dst_dataset:\n",
    "        out_transform = dst_dataset.transform\n",
    "        xmin, ymin, xmax, ymax  = dst_dataset.bounds\n",
    "        width = dst_dataset.width # x axis\n",
    "        height = dst_dataset.height # y axis\n",
    "        out_shape = (height, width)\n",
    "        # print(out_shape)\n",
    "        for ind in label_df.index:\n",
    "            label_name = label_df[\"names\"][ind]\n",
    "            label_shp = label_df[\"shp\"][ind]\n",
    "            out_channel = int(label_df[\"channel\"][ind])\n",
    "            label_path = in_shp_dir.joinpath(label_shp)\n",
    "            # print(label_shp)\n",
    "            # print(out_channel)\n",
    "            # load shapefile to geopandas\n",
    "            label_gdf = gpd.read_file(label_path)\n",
    "            # overlay by image bounds ?\n",
    "            label_gdf = label_gdf.cx[xmin:xmax, ymin:ymax]\n",
    "            # this is where we create a generator of geom, value pairs to use in rasterizing\n",
    "            if len(label_gdf) !=0 :\n",
    "                shapes = ((geom, 1) for geom in label_gdf.geometry)\n",
    "                burned = features.rasterize(shapes=shapes, out_shape=out_shape, fill=0, transform=out_transform)\n",
    "            else :\n",
    "                burned = np.zeros(out_shape, dtype=np.uint8)\n",
    "            # print(burned.shape)\n",
    "            dst_dataset.write(burned.astype(rasterio.uint8), out_channel+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d64c78a-2f7b-42b4-8293-63ab3a879bc1",
   "metadata": {},
   "source": [
    "### test rasterization display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f608f5-a869-4169-a9dc-b3d1bece9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rvb_list = gers_rvb_df[\"rvb_path\"].values\n",
    "out_mask_dir = gers_dataset_root_dir.joinpath(\"IMAGES_MASK\")\n",
    "test_mask = out_mask_dir.joinpath(\"FR_032_2019_U-17-MASK.tif\")\n",
    "\n",
    "with rasterio.open(test_mask) as mask_ds:\n",
    "    mask_array = mask_ds.read()\n",
    "    mask_array = np.argmax(mask_array, axis=0)\n",
    "    mask_array = np.take(naf_lut, mask_array, axis=0)\n",
    "\n",
    "print(mask_array.shape)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(mask_array[1024:2048,2048:3072])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0c583-5b85-44c1-81ca-b0cf1a7b2fd2",
   "metadata": {},
   "source": [
    "## dataset with chop/clip when reading image\n",
    "\n",
    "Instead of first preprocess imagery to have a DL dataset into Ã  list of small patch image files we could also try to tile imagery on the fly based on the original large aerial/satellite imagery. \n",
    "\n",
    "Why could we be interrested in such functionnality :\n",
    " \n",
    " * first to test speed/data efficiency management. Large dataset could be simpler to manage and compress than a lot of small files and reading could also be as efficient.\n",
    " * the decision made when splitting could be changed on the fly. As pass to 256 to 512 pixels patchs\n",
    " * could act as a form of data augmentation without duplicate memory by sampling tile a different ovelerapping positions.\n",
    " * could help to change/test sampling by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef0d38-f562-4b63-bd8b-3683e5e5c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for use in train code\n",
    "from eotorchloader.dataset.scene_dataset import LargeImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c04f88-b1eb-4a96-9338-9edf47e3099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files_train = gers_rvb_df[\"rvb_path\"].values\n",
    "mask_files_train = gers_rvb_df[\"msk_path\"].values\n",
    "print(image_files_train[0:5])\n",
    "print(mask_files_train[0:5])\n",
    "\n",
    "train_dataset_tile = LargeImageDataset(\n",
    "    image_files=image_files_train,\n",
    "    mask_files=mask_files_train,\n",
    "    tile_size = 512,\n",
    "    transforms=None,\n",
    "    image_bands=image_bands,\n",
    "    mask_bands=mask_bands[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef082fc-0585-4778-972c-2b2cd97dba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display import\n",
    "from eotorchloader.transform.tensor import CHW_to_HWC\n",
    "from eotorchloader.transform.display import ToRgbDisplay\n",
    "\n",
    "from eotorchloader.display.matplotlib import view_patch, view_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fea0c5-8a11-46b5-b5e9-10b24ad970b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_last_transform = CHW_to_HWC(img_only=True)\n",
    "display_patch_transform = ToRgbDisplay( lut=naf_lut)\n",
    "\n",
    "test_data = train_dataset_tile[142]\n",
    "view_patch(test_data, transforms=[channel_last_transform, display_patch_transform])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa3e031-9041-419c-9b96-418f6aca885d",
   "metadata": {},
   "source": [
    "# Lighning Datamodule\n",
    "\n",
    "we use datamodule to manage fold loading setup and some other utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7557b9d-a012-4f17-8b6c-ff1ecf809b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eotorchloader.datamodule.terria import TerriaDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4e08c-f576-4e1d-a1ff-537ee15ee82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gers_set_config = {\n",
    "    \"set1\" : {\n",
    "        \"train\" : [3, 4, 5],\n",
    "        \"val\" : [2],\n",
    "        \"test\" : [1] },\n",
    "    \"set2\" : {\n",
    "        \"train\" : [4, 5, 1],\n",
    "        \"val\" : [3],\n",
    "        \"test\" : [2] },\n",
    "    \"set3\" : {\n",
    "        \"train\" : [5, 1, 2],\n",
    "        \"val\" : [4],\n",
    "        \"test\" : [3] },\n",
    "    \"set4\" : {\n",
    "        \"train\" : [1, 2, 3],\n",
    "        \"val\" : [5],\n",
    "        \"test\" : [4] },\n",
    "    \"set5\" : {\n",
    "        \"train\" : [2, 3, 4],\n",
    "        \"val\" : [1],\n",
    "        \"test\" : [5] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d54e0e-ff2b-4191-9095-01677f3e1dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms for test\n",
    "in_transforms = [\n",
    "    ScaleImageToFloat(scale_factor=255, clip=True),\n",
    "    ToTorchTensor()\n",
    "]\n",
    "gers_data_module_set5 = TerriaDataModule(\n",
    "    gers_rvb_df, \n",
    "    transforms = in_transforms,\n",
    "    img_col = \"rvb_path\",\n",
    "    img_bands = image_bands,\n",
    "    mask_col = \"msk_path\",\n",
    "    mask_bands = mask_bands[:-1],\n",
    "    group_col = \"kfold\",\n",
    "    set_config = gers_set_config[\"set5\"])\n",
    "\n",
    "gers_data_module_set5.setup()\n",
    "train_dataloader = gers_data_module_set5.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c09ed-c8af-49b8-bba9-eb736ad55c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_transforms = [\n",
    "    TensorToArray(),\n",
    "    FloatImageToByte(clip=True),\n",
    "    CHW_to_HWC(img_only=True),\n",
    "    ToRgbDisplay(lut=naf_lut)\n",
    "]\n",
    "test_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8291ceee-6d60-4513-be63-d9e796e93424",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_batch(test_batch, size = 4, transforms = display_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe33b4-1f40-4139-ad18-6c7b4ee95887",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_dataloader = gers_data_module_set5.train_dataloader()\n",
    "\n",
    "with tqdm(\n",
    "    total=len(img_train_dataloader), desc=f\"Large Image loader\",\n",
    "    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}]') as pbar:\n",
    "\n",
    "    for sample in img_train_dataloader:\n",
    "        images = sample['image']\n",
    "        masks = sample['mask']\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01c8e4-0c9b-4cc0-b692-508c0549229e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EOtorchLoader)",
   "language": "python",
   "name": "eotorchloader"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
